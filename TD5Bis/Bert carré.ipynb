{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://medium.com/saarthi-ai/build-a-smart-question-answering-system-with-fine-tuned-bert-b586e4cfa5f5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://huggingface.co/transformers/torchscript.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa = pd.read_csv(\"watashiwa.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "reponses = pd.read_excel(\"watashiwa.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "paras = []\n",
    "para = \"\"\n",
    "for a in reponses['answer']:\n",
    "    if (len(para.split(\" \")) + len(a.split(\" \"))) > 400:\n",
    "        paras.append(para)\n",
    "        para = \"\"\n",
    "        para += \" \" + a\n",
    "    else:\n",
    "        para += \" \" + a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertForQuestionAnswering\n",
    "from transformers import BertTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the BertForQuestionAnswering model and the tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model\n",
    "model = BertForQuestionAnswering.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')\n",
    "\n",
    "#Tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a QA example and use function encode_plus() to encode the example. The function encode_plus() returns a dictionary that contains input_ids, token_type_ids, and attention mask but we only need input_ids and token_type_ids for the QA task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answerme(question):\n",
    "    answers = []\n",
    "    for para in paras:\n",
    "        encoding = tokenizer.encode_plus(text=question,text_pair=paragraph, add_special=True)\n",
    "\n",
    "        inputs = encoding['input_ids']  #Token embeddings\n",
    "        sentence_embedding = encoding['token_type_ids']  #Segment embeddings\n",
    "        tokens = tokenizer.convert_ids_to_tokens(inputs) #input tokens\n",
    "\n",
    "        start_scores, end_scores = model(input_ids=torch.tensor([inputs]), token_type_ids=torch.tensor([sentence_embedding]))\n",
    "\n",
    "        start_index = torch.argmax(start_scores)\n",
    "\n",
    "        end_index = torch.argmax(end_scores)\n",
    "\n",
    "        answer = ' '.join(tokens[start_index:end_index+1])\n",
    "        corrected_answer = ''\n",
    "\n",
    "        for word in answer.split():\n",
    "\n",
    "            #If it's a subword token\n",
    "            if word[0:2] == '##':\n",
    "                corrected_answer += word[2:]\n",
    "            else:\n",
    "                corrected_answer += ' ' + word\n",
    "        answers.append(answer)\n",
    "    return answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Keyword arguments {'add_special': True} not recognized.\n",
      "Keyword arguments {'add_special': True} not recognized.\n"
     ]
    }
   ],
   "source": [
    "answerme(\"what is your name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Keyword arguments {'add_special': True} not recognized.\n",
      "Keyword arguments {'add_special': True} not recognized.\n"
     ]
    }
   ],
   "source": [
    "question = '''watashiwa des'''\n",
    "\n",
    "paragraph = paras[0]\n",
    "            \n",
    "encoding = tokenizer.encode_plus(text=question,text_pair=paragraph, add_special=True)\n",
    "\n",
    "inputs = encoding['input_ids']  #Token embeddings\n",
    "sentence_embedding = encoding['token_type_ids']  #Segment embeddings\n",
    "tokens = tokenizer.convert_ids_to_tokens(inputs) #input tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Keyword arguments {'add_special': True} not recognized.\n",
      "Keyword arguments {'add_special': True} not recognized.\n"
     ]
    }
   ],
   "source": [
    "question = '''Why was the student group called \"the Methodists?\"'''\n",
    "\n",
    "paragraph = ''' The movement which would become The United Methodist Church began in the mid-18th century within the Church of England.\n",
    "            A small group of students, including John Wesley, Charles Wesley and George Whitefield, met on the Oxford University campus.\n",
    "            They focused on Bible study, methodical study of scripture and living a holy life.\n",
    "            Other students mocked them, saying they were the \"Holy Club\" and \"the Methodists\", being methodical and exceptionally detailed in their Bible study, opinions and disciplined lifestyle.\n",
    "            Eventually, the so-called Methodists started individual societies or classes for members of the Church of England who wanted to live a more religious life. '''\n",
    "            \n",
    "encoding = tokenizer.encode_plus(text=question,text_pair=paragraph, add_special=True)\n",
    "\n",
    "inputs = encoding['input_ids']  #Token embeddings\n",
    "sentence_embedding = encoding['token_type_ids']  #Segment embeddings\n",
    "tokens = tokenizer.convert_ids_to_tokens(inputs) #input tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the QA example through the loaded model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_scores, end_scores = model(input_ids=torch.tensor([inputs]), token_type_ids=torch.tensor([sentence_embedding]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have start scores and end scores we can get both the start index and the end index and use both the indices for span prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_index = torch.argmax(start_scores)\n",
    "\n",
    "end_index = torch.argmax(end_scores)\n",
    "\n",
    "answer = ' '.join(tokens[start_index:end_index+1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: The model is likely to predict an end word that is before the start word. The correct way is to pick a span for which the total score (start score + end score) is maximum where end_index ≥ start_index."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: BERT uses wordpiece tokenization. Wordpiece split the tokens like “playing” to “play and ##ing”. It also covers a wider spectrum of Out-Of-Vocabulary (OOV) words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can recover any words that were broken down into subwords with a little bit more work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_answer = ''\n",
    "\n",
    "for word in answer.split():\n",
    "    \n",
    "    #If it's a subword token\n",
    "    if word[0:2] == '##':\n",
    "        corrected_answer += word[2:]\n",
    "    else:\n",
    "        corrected_answer += ' ' + word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' [CLS]'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrected_answer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
